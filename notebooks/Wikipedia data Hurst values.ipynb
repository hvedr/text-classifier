{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from textutils import TextProcessor\n",
    "from textutils import TextUtils\n",
    "from textutils import HurstExponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get hurst values for single texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = !ls 'wiki_data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "czech(cs).txt is processing... ( alphabet =  cs_con )\n",
      "\t calculating hurst values for symbol ( n )\n"
     ]
    }
   ],
   "source": [
    "for language in files[2:]:\n",
    "    alph = language[-7:-5] + '_con'\n",
    "    print language, 'is processing... ( alphabet = ', alph, ')'\n",
    "\n",
    "    with open('wiki_data/processed/' + language, 'r') as processed_file:\n",
    "        text = processed_file.read().replace('\\n', '').decode('utf-8')\n",
    "\n",
    "    normalized_dict = TextUtils.get_normalized_dict (\n",
    "        TextUtils.get_n_gram_dict(text.encode('utf-8'), 1, lang=alph)\n",
    "    )\n",
    "    ordered_dict = TextUtils.get_ordered_dict(normalized_dict, by='value', reverse=True)\n",
    "    lead_letter = list(ordered_dict)[0][0]\n",
    "\n",
    "    print '\\t calculating hurst values for symbol (', lead_letter, ')'\n",
    "    hurst = HurstExponent(text, lead_letter)\n",
    "    hurst.calculate(10000)\n",
    " \n",
    "    with open('hurst_values/' + language, 'w') as outfile:\n",
    "        for v in hurst.hurst_values:\n",
    "            outfile.write(str(v) + '\\n')\n",
    "    \n",
    "    print '\\t has been processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get hurst values for mixed text pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def merge_texts(lang_1_path, lang_2_path, merged_path, window, size=np.inf):\n",
    "\n",
    "    with open(lang_1_path, 'r') as processed_file:\n",
    "        lang_1 = processed_file.read().replace('\\n', '').decode('utf-8')\n",
    "\n",
    "    with open(lang_2_path, 'r') as processed_file:\n",
    "        lang_2 = processed_file.read().replace('\\n', '').decode('utf-8')\n",
    "\n",
    "    with codecs.open(merged_path, 'w', 'utf-8') as merged:\n",
    "        for i in range(0, min([len(lang_1), len(lang_2), size]) - window, window):\n",
    "            merged.write(TextProcessor.get_english_transliteration(lang_1[i:(i + window)]))\n",
    "            merged.write(TextProcessor.get_english_transliteration(lang_2[i:(i + window)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "langs_path = 'wiki_data/processed/'\n",
    "pairs_path = '/mnt/usb/voynich/processed_pairs/'\n",
    "languages = !ls 'wiki_data/processed/'\n",
    "window_size = 1000\n",
    "done_langs = []\n",
    "\n",
    "for lang_1 in languages:\n",
    "    for lang_2 in languages:\n",
    "        lang_1_name = lang_1[:-8]\n",
    "        lang_2_name = lang_2[:-8]\n",
    "\n",
    "        if lang_1_name != lang_2_name and \\\n",
    "                lang_1_name + \"_\" + lang_2_name not in done_langs and \\\n",
    "                    lang_2_name + \"_\" + lang_1_name not in done_langs:\n",
    "\n",
    "            merge_texts (\n",
    "                langs_path + lang_1,\n",
    "                langs_path + lang_2,\n",
    "                pairs_path + lang_1_name + \"_\" + lang_2_name + \".txt\",\n",
    "                window_size)\n",
    "\n",
    "            done_langs.append(lang_1_name + \"_\" + lang_2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = !ls '/mnt/usb/voynich/processed_pairs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file bulgarian_croatian.txt is processing...\n"
     ]
    }
   ],
   "source": [
    "for language in files:\n",
    "    print 'file', language, 'is processing...'\n",
    "\n",
    "    with open('/mnt/usb/voynich/processed_pairs/' + language, 'r') as processed_file:\n",
    "        text = processed_file.read().replace('\\n', '').decode('utf-8')\n",
    "\n",
    "    normalized_dict = TextUtils.get_normalized_dict (\n",
    "        TextUtils.get_n_gram_dict(text.encode('utf-8'), 1, lang='en_con')\n",
    "    )\n",
    "    ordered_dict = TextUtils.get_ordered_dict(normalized_dict, by='value', reverse=True)\n",
    "    lead_letter = list(ordered_dict)[0][0]\n",
    "\n",
    "    print '\\t calculating hurst values for symbol (', lead_letter, ')'\n",
    "    hurst = HurstExponent(text, lead_letter)\n",
    "    hurst.calculate(10000)\n",
    " \n",
    "    with open('hurst_values/pairs/' + language, 'w') as outfile:\n",
    "        for v in hurst.hurst_values:\n",
    "            outfile.write(str(v) + '\\n')\n",
    "    \n",
    "    print '\\t has been processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
